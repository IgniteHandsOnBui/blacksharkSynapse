{
	"name": "cv_pumpjack_clip",
	"properties": {
		"description": "Working document for clipping pumpjacks - trying to replicate FME job",
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "Geospatialspark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "6776bcce-72ed-49e4-9059-40345bb0063f"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/251b3efb-f673-4fa5-a56e-e2f645fc33fa/resourceGroups/innosyn-pipeline-rg/providers/Microsoft.Synapse/workspaces/innosyn-pipeline-syn-ws/bigDataPools/Geospatialspark",
				"name": "Geospatialspark",
				"type": "Spark",
				"endpoint": "https://innosyn-pipeline-syn-ws.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/Geospatialspark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 10,
				"cores": 8,
				"memory": 56,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from notebookutils import mssparkutils\r\n",
					"mssparkutils.fs.mount(\r\n",
					"    \"wasbs://azureml-blobstore-91aa9420-fbec-40ef-91e9-982a277c80cf@dinnot101mlcvx.blob.core.windows.net\",\r\n",
					"    \"/testliam\",\r\n",
					"    {\"linkedService\":\"LiamTest\"}\r\n",
					")"
				],
				"execution_count": 60
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"jobId = mssparkutils.env.getJobId()\r\n",
					"# print(jobId)\r\n",
					"# mssparkutils.fs.ls(\"synfs:/\"+jobId+\"/testliam/UI/geotagged_subset_pumpjacks_clip/06-23-2022_015728_UTC/2022_SJVBU_KernRiverAFlight1_6-15-2022\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Plot jpeg image from blob storage container\r\n",
					"import rasterio\r\n",
					"from rasterio.plot import show\r\n",
					"img_path = f'/synfs/'+jobId+'/testliam/UI/06-13-2022_075155_UTC/2022_SJVBU_Kern_River_A_Flight_01_00217.jpg'\r\n",
					"src = rasterio.open(img_path)\r\n",
					"show(src)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import os\r\n",
					"import rasterio\r\n",
					"\r\n",
					"def get_blob_file_list(directory):\r\n",
					"    for f in os.listdir(directory):\r\n",
					"        f_img = img_dir+f\r\n",
					"        print(f_img)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import json\r\n",
					"import numpy as np\r\n",
					"\r\n",
					"def parse_AML_json(json_path):\r\n",
					"    parsed_list = np.array(['name','topX','topY','bottomX','bottomY'])\r\n",
					"\r\n",
					"    with open(json_path, 'r') as json_file:\r\n",
					"        json_list = list(json_file)\r\n",
					"        for pumpjack in json_list:\r\n",
					"            pumpjack_json = json.loads(pumpjack)\r\n",
					"\r\n",
					"            pumpjack_img = os.path.basename(pumpjack_json['image_url'])\r\n",
					"            \r\n",
					"            for pumpjack_label in pumpjack_json['label']:\r\n",
					"                topX = pumpjack_label['topX']\r\n",
					"                topY = pumpjack_label['topY']\r\n",
					"                bottomX = pumpjack_label['bottomX']\r\n",
					"                bottomY = pumpjack_label['bottomY']\r\n",
					"                \r\n",
					"                parsed_row = np.array([pumpjack_img,topX,topY,bottomX,bottomY])\r\n",
					"                #print(parsed_row)\r\n",
					"                parsed_list = np.vstack([parsed_list, parsed_row])\r\n",
					"    return parsed_list"
				],
				"execution_count": 96
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import rasterio\r\n",
					"\r\n",
					"def clip_pumpjacks(pumpjack_list, img_dir):\r\n",
					"    for pumpjack in pumpjack_list:\r\n",
					"        if pumpjack[0] == 'name':\r\n",
					"            continue\r\n",
					"        \r\n",
					"        img_file = img_dir + pumpjack[0]\r\n",
					"        print(img_file)\r\n",
					"        topX = pumpjack[1]\r\n",
					"        topY = pumpjack[2]\r\n",
					"        bottomX = pumpjack[3]\r\n",
					"        bottomY = pumpjack[4]\r\n",
					"\r\n",
					"        img = rasterio.open(img_file)\r\n",
					"        img_width = img.width\r\n",
					"        img_height = img.height\r\n",
					"\r\n",
					"        topX_pixel = int(int(img_width)*float(topX))\r\n",
					"        topY_pixel = int(int(img_height)*float(topY))\r\n",
					"        bottomX_pixel = int(int(img_width)*float(bottomX))\r\n",
					"        bottomY_pixel = int(int(img_height)*float(bottomY))\r\n",
					"\r\n",
					"        middleX_pixel = int(topX_pixel + .5*(bottomX_pixel-topX_pixel))\r\n",
					"        middleY_pixel = int(bottomY_pixel + .5*(bottomY_pixel-topY_pixel))\r\n",
					"\r\n",
					"        # print(\"topX = \"+ str(topX_pixel))\r\n",
					"        # print(\"topY = \"+ str(topY_pixel))\r\n",
					"        # print(\"bottomX_pixel = \"+ str(bottomX_pixel))\r\n",
					"        # print(\"bottomY_pixel = \"+ str(bottomY_pixel))\r\n",
					"        # print(\" \")\r\n",
					"        # print(\"middleX_pixel = \"+ str(middleX_pixel))\r\n",
					"        # print(\"middleY_pixel = \"+ str(middleY_pixel))\r\n",
					"\r\n",
					"\r\n",
					"        img.close()"
				],
				"execution_count": 129
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"img_dir = f'/synfs/'+jobId+'/testliam/UI/06-15-2022_053557_UTC/geotagged_subset/'\r\n",
					"aml_json_path = f'/synfs/'+jobId+'/testliam/Labeling/export/dataset/b2efe480-107f-e1c2-5e78-7af2427f8f00/b5779ff4-ec96-455f-82df-92de2386cafd/labeledDatapoints_1.jsonl'\r\n",
					"\r\n",
					"#pumpjack_list = parse_AML_json(aml_json_path)\r\n",
					"\r\n",
					"#get_blob_file_list(img_dir)\r\n",
					"\r\n",
					"clip_pumpjacks(pumpjack_list, img_dir)"
				],
				"execution_count": 130
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"mssparkutils.fs.unmount(\"/test\")\r\n",
					"mssparkutils.fs.unmount(\"/test_liam\")"
				],
				"execution_count": null
			}
		]
	}
}