{
	"name": "STAC_PreProcessing_Guide",
	"properties": {
		"description": "Guide for documenting and sharing pre-processing steps required prior to the STAC ingestion process. This guide will use JPGs as an example",
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "Geospatialspark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "56g",
			"driverCores": 8,
			"executorMemory": "56g",
			"executorCores": 8,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "41ffea3a-18a5-4fb8-8909-482d08fd66da"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/251b3efb-f673-4fa5-a56e-e2f645fc33fa/resourceGroups/innosyn-pipeline-rg/providers/Microsoft.Synapse/workspaces/innosyn-pipeline-syn-ws/bigDataPools/Geospatialspark",
				"name": "Geospatialspark",
				"type": "Spark",
				"endpoint": "https://innosyn-pipeline-syn-ws.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/Geospatialspark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 10,
				"cores": 8,
				"memory": 56,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"#TODO:\r\n",
					"\"\"\"\r\n",
					"Prepare step-by step notebook with all STAC pre-processing steps that include all transformations and metadata creation steps. \r\n",
					"Use markdown text for instructions.\r\n",
					"Stretch - automate services requires via email generation ITFP GTA\r\n",
					"Demo Notebook stakeholders: DnI-GIS, GTA, DINNO.\r\n",
					"\"\"\""
				],
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# STAC Ingestion Synapse Notebook Guide\r\n",
					"This guide will demonstrate the data processing steps of rich media data into STAC. \r\n",
					"\r\n",
					"For more information on Chevron's STAC implementation - **[Chevron Atlas](https://atlas-dev.azure.chevron.com/)**\r\n",
					"\r\n",
					"This guide follows recommendations provided in CDAS - **[Data Preparation](https://cdas.azure.chevron.com/Data-Insights/Geospatial-Technology-And-Analytics/Chevron-Atlas/Getting-Started/Data-Preparation.html)**\r\n",
					"## Sections:\r\n",
					"### 1. Mount blob storages\r\n",
					"### 2. Get list of all images in source container\r\n",
					"### 3. Setting up the collection\r\n",
					"### 4. Extract file header information\r\n",
					"### 5. Add Metadata to file header\r\n",
					"### 6. Determine if Mobile, or Aerial image\r\n",
					"### 7. Write to destination folder"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### 1. Mounting rich media source and destination storage accounts\r\n",
					"Typically the source will be XXXX and the destination will be YYYY"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from notebookutils import mssparkutils\r\n",
					"\r\n",
					"try:\r\n",
					"    mssparkutils.fs.mount(\r\n",
					"        \"wasbs://liamsource@innoaoaidata.blob.core.windows.net\",\r\n",
					"        \"/STAC_Source\",\r\n",
					"        {\"linkedService\":\"innoaoaidata_STAC\"}\r\n",
					"    )\r\n",
					"    print(\"Successful mount of source to /STAC_Source\")\r\n",
					"except:\r\n",
					"    print(\"FAILED TO MOUNT STAC SOURCE\")\r\n",
					"    print(\"Either due to the drive already been mounted, or because the path is incorrect\")\r\n",
					"\r\n",
					"\r\n",
					"try:\r\n",
					"    mssparkutils.fs.mount(\r\n",
					"        \"wasbs://liamdest@innoaoaidata.blob.core.windows.net\",\r\n",
					"        \"/STAC_Dest\",\r\n",
					"        {\"linkedService\":\"innoaoaidata_STAC\"}\r\n",
					"    )\r\n",
					"    print(\"Successful mount of source to /STAC_Dest\")\r\n",
					"except:\r\n",
					"    print(\"FAILED TO MOUNT STAC DESTINATION\")\r\n",
					"    print(\"Either due to the drive already been mounted, or because the path is incorrect\")"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 2. Get list of all rich media data in source folder"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Return array of all files in directory of type\r\n",
					"import os\r\n",
					"\r\n",
					"def get_blob_file_list(directory, filetype):\r\n",
					"    file_array = []\r\n",
					"    for file in os.listdir(directory):\r\n",
					"        file_ext = os.path.splitext(file)[1]\r\n",
					"        if file_ext == filetype:\r\n",
					"            file_array.append(directory+file)\r\n",
					"    return file_array"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"jobId = mssparkutils.env.getJobId()\r\n",
					"img_path = f'/synfs/'+jobId+'/STAC_Source/RBU_STAC_SOURCE/'\r\n",
					"outarray = get_blob_file_list(img_path, \".JPG\")\r\n",
					"outarray"
				],
				"execution_count": 6
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Lets take a look at what these photos look like:"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Dispay first 5 images in blob storage\r\n",
					"import rasterio\r\n",
					"from rasterio.plot import show\r\n",
					"\r\n",
					"def view_images(directory):\r\n",
					"    count = 0\r\n",
					"    for image in get_blob_file_list(directory):\r\n",
					"        if count >=5:\r\n",
					"            src = rasterio.open(directory+image)\r\n",
					"            show(src)\r\n",
					"            src.close()\r\n",
					"            count = count + 1"
				],
				"execution_count": 7
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 3. Setting up the collection\r\n",
					"\r\n",
					"We have already setup 2 collections in the destination folder titled XXX and YYY"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"jobId = mssparkutils.env.getJobId()\r\n",
					"oblique_mobile_path = f'/synfs/'+jobId+'/STAC_Dest/RBU_STAC_DEST/Mobile/Oblique/rbu_mobile_oblique_imagery_for_ehsr_reporting'\r\n",
					"oblique_aerial_path = f'/synfs/'+jobId+'/STAC_Dest/RBU_STAC_DEST/Mobile/Oblique/rbu_mobile_oblique_imagery_for_ehsr_reporting'\r\n",
					"\r\n",
					"oblique_mobile_collection_json = f'/synfs/'+jobId+'/STAC_Dest/RBU_STAC_DEST/Mobile/Oblique/rbu_mobile_oblique_imagery_for_ehsr_reporting/rbu_mobile_oblique_imagery_for_ehsr_reporting_mtl.json'\r\n",
					"oblique_aerial_collection_json = f'/synfs/'+jobId+'/STAC_Dest/RBU_STAC_DEST/Aerial/Oblique/rbu_aerial_oblique_imagery_for_ehsr_reporting/rbu_aerial_oblique_imagery_for_ehsr_reporting_mtl.json'"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Take a look at the collection MTL json files\r\n",
					"import json\r\n",
					"\r\n",
					"def check_collection_mtl(jsonpath):\r\n",
					"    json_open = json.load(open(jsonpath))\r\n",
					"    print(json_open)\r\n",
					"    return json_open"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"mobile_collection = check_collection_mtl(oblique_mobile_collection_json)\r\n",
					"print(\"\")\r\n",
					"aerial_collection = check_collection_mtl(oblique_aerial_collection_json)\r\n",
					""
				],
				"execution_count": 10
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 4. Extract EXIF Header Information\r\n",
					"Depending on the rich media data type, this step will be different. Between LAS files, GEOTIFFs, JPEGs, etc ... this step will have to be re-written to extract metadata from those files. "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import rasterio\r\n",
					"def extract_EXIF(jpeg_path):\r\n",
					"    file = rasterio.open(jpeg_path)\r\n",
					"    jpeg_EXIF = file.tags()\r\n",
					"    file.close()\r\n",
					"    return jpeg_EXIF"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"extract_EXIF(f'/synfs/62/STAC_Source/RBU_STAC_SOURCE/202002280104265320_skilpatrick_S3_7-15-19_DJI_0256.JPG')"
				],
				"execution_count": 13
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 5. Add Metadata\r\n",
					"### 5.1 Add Bounding Box\r\n",
					"### 5.2 Add DateTime\r\n",
					"### 5.3 Add CRS\r\n",
					"### 5.4 Add Sensor Type"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### 5.1 Bounding Box\r\n",
					"To calculate a bounding box from a JPEG you must first do 3 things:\r\n",
					"- Extract lat/long from EXIF Header (including if coordinate direction is North/South or East/West)\r\n",
					"- Convert lat/long from EXIF Header from Degree, Minutes, Seconds to Decimal Degrees\r\n",
					"- Calculate new bounding box\r\n",
					"\r\n",
					"Lastly, the data must be inserted into the \"headers\" of the JPEG. Since JPEG does not natively support adding to headers, a XML file is created via rasterio. This step will be done once we move the new images into the right folder."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import rasterio\r\n",
					"\r\n",
					"def get_EXIF_lat(jpeg_path):\r\n",
					"    jpeg = rasterio.open(jpeg_path)\r\n",
					"    filetags = jpeg.tags()\r\n",
					"    GPSLatitude = filetags.get(\"EXIF_GPSLatitude\")\r\n",
					"    GPSLatitudeRef = filetags.get(\"EXIF_GPSLatitudeRef\")\r\n",
					"    jpeg.close()\r\n",
					"    return GPSLatitude, GPSLatitudeRef\r\n",
					"\r\n",
					"def get_EXIF_long(jpeg_path):\r\n",
					"    jpeg = rasterio.open(jpeg_path)\r\n",
					"    filetags = jpeg.tags()\r\n",
					"    GPSLongitude = filetags.get(\"EXIF_GPSLongitude\")\r\n",
					"    GPSLongitudeRef = filetags.get(\"EXIF_GPSLongitudeRef\")\r\n",
					"\r\n",
					"    jpeg.close()\r\n",
					"    return GPSLongitude, GPSLongitudeRef"
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def Exif_Cord_Convert(EXIF_Cord, direction):\r\n",
					"    new_str = EXIF_Cord.replace(\"(\",\"\")\r\n",
					"    new_str = new_str.replace(\")\",\"\")\r\n",
					"\r\n",
					"    split_str = new_str.split(\" \")\r\n",
					"    \r\n",
					"    decimaldegrees = (float(split_str[0]) + float(split_str[1])/60 + float(split_str[2])/(60*60)) * (-1 if direction in ['W', 'S'] else 1)\r\n",
					"    return(decimaldegrees)"
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import pyproj\r\n",
					"from shapely.ops import transform\r\n",
					"from shapely.geometry import Point\r\n",
					"\r\n",
					"def calculate_bb(lat, lon):\r\n",
					"    proj_wgs84 = pyproj.Proj('+proj=longlat +datum=WGS84')\r\n",
					"    \r\n",
					"    # Azimuthal equidistant projection\r\n",
					"    aeqd_proj = '+proj=aeqd +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0'\r\n",
					"    project = partial(\r\n",
					"        pyproj.transform,\r\n",
					"        pyproj.Proj(aeqd_proj.format(lat=lat, lon=lon)),\r\n",
					"        proj_wgs84)\r\n",
					"    \r\n",
					"    buf = Point(0, 0).buffer(1)  # buffers 1 meter\r\n",
					"    return transform(project, buf).bounds"
				],
				"execution_count": 20
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### 5.2 Add Date Time\r\n",
					"\r\n",
					"The STAC spec calls for a datetime to be added to the headers of the files. For this use case, EXIF information includes this data, but we have to get it into the right format. To do this, we will extract the EXIF Datetime and convert it to the STAC-ready format.\r\n",
					"\r\n",
					"This step will be done once we move the new images into the right folder."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from datetime import datetime\r\n",
					"#Output date time must be in \r\n",
					"def get_jpeg_datetime(jpeg_path):\r\n",
					"    jpeg = rasterio.open(jpeg_path)\r\n",
					"    filetags = jpeg.tags()\r\n",
					"    EXIF_Datetime = filetags.get(\"EXIF_DateTime\")\r\n",
					"    EXIF_datetime_obj = datetime.strptime(EXIF_Datetime, '%Y:%m:%d %H:%M:%S')\r\n",
					"    STAC_datetime = EXIF_datetime_obj.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\r\n",
					"    return STAC_datetime"
				],
				"execution_count": 40
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### 5.3 Add Coordinate Reference System\r\n",
					"The Cordinate Reference System (CRS) of a "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}