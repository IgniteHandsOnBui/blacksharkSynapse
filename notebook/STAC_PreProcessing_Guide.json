{
	"name": "STAC_PreProcessing_Guide",
	"properties": {
		"description": "Guide for documenting and sharing pre-processing steps required prior to the STAC ingestion process. This guide will use JPGs as an example",
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "Geospatialspark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "56g",
			"driverCores": 8,
			"executorMemory": "56g",
			"executorCores": 8,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "2bff6d84-6bcd-4e00-ba45-b3d03815cc83"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/251b3efb-f673-4fa5-a56e-e2f645fc33fa/resourceGroups/innosyn-pipeline-rg/providers/Microsoft.Synapse/workspaces/innosyn-pipeline-syn-ws/bigDataPools/Geospatialspark",
				"name": "Geospatialspark",
				"type": "Spark",
				"endpoint": "https://innosyn-pipeline-syn-ws.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/Geospatialspark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 10,
				"cores": 8,
				"memory": 56,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# STAC Ingestion Synapse Notebook Guide\r\n",
					"This guide will demonstrate the data processing steps of the oblique imagery data type into a STAC-ready format.\r\n",
					"\r\n",
					"For more information on Chevron's STAC implementation - **[Chevron Atlas](https://atlas-dev.azure.chevron.com/)**\r\n",
					"\r\n",
					"This guide follows recommendations provided in CDAS - **[Data Preparation](https://cdas.azure.chevron.com/Data-Insights/Geospatial-Technology-And-Analytics/Chevron-Atlas/Getting-Started/Data-Preparation.html)**\r\n",
					"## Sections:\r\n",
					"### 1. Mount blob storages\r\n",
					"### 2. Get list of all images in source container\r\n",
					"### 3. Setting up the collection\r\n",
					"### 4. Extract file header information\r\n",
					"### 5. Create new Metadata from file header\r\n",
					"### 6. Determine if Mobile, or Aerial image (Platform)\r\n",
					"### 7. Write to destination folder w/Metadata"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 1. Mounting rich media source and destination storage accounts\r\n",
					"Typically the source of the rich media will be in one container, and the destination will be in another. In this example I have the source in a blob storage account under the container \"liamsource\" and the destination in a blob storage account under the \"liamdest\" container. In code, these folders will be \"STAC_Source\" and \"STAC_Dest\" respectively."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"jobId = mssparkutils.env.getJobId()\r\n",
					"JPG_Source_Dir = f'/synfs/'+jobId+'/STAC_Source/RBU_STAC_SOURCE/'\r\n",
					"JPG_Dest_Dir = f'/synfs/'+jobId+'/STAC_Dest/RBU_STAC_DEST/'"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from notebookutils import mssparkutils\r\n",
					"\r\n",
					"try:\r\n",
					"    mssparkutils.fs.mount(\r\n",
					"        \"wasbs://liamsource@innoaoaidata.blob.core.windows.net\",\r\n",
					"        \"/STAC_Source\",\r\n",
					"        {\"linkedService\":\"innoaoaidata_STAC\"}\r\n",
					"    )\r\n",
					"    print(\"Successful mount of source to /STAC_Source\")\r\n",
					"except:\r\n",
					"    print(\"FAILED TO MOUNT STAC SOURCE\")\r\n",
					"    print(\"Either due to the drive already been mounted, or because the path is incorrect\")\r\n",
					"\r\n",
					"\r\n",
					"try:\r\n",
					"    mssparkutils.fs.mount(\r\n",
					"        \"wasbs://liamdest@innoaoaidata.blob.core.windows.net\",\r\n",
					"        \"/STAC_Dest\",\r\n",
					"        {\"linkedService\":\"innoaoaidata_STAC\"}\r\n",
					"    )\r\n",
					"    print(\"Successful mount of source to /STAC_Dest\")\r\n",
					"except:\r\n",
					"    print(\"FAILED TO MOUNT STAC DESTINATION\")\r\n",
					"    print(\"Either due to the drive already been mounted, or because the path is incorrect\")"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Mounting the STAC_Innovation_Ingest folder the Data & Insights Innovation team has on the Chevon Datalake.\r\n",
					"\r\n",
					"try:\r\n",
					"    mssparkutils.fs.mount(\r\n",
					"        'wasbs://raw@chevrondatalakedev.blob.core.windows.net',\r\n",
					"        '/STAC_InnoDL',\r\n",
					"        {'linkedService':'chevrondatalake'}\r\n",
					"    )\r\n",
					"    print(\"Successful mount of source to /STAC_InnoDL\")\r\n",
					"except:\r\n",
					"    print(\"FAILED TO MOUNT STAC INNOVATION DATALAKE FOLDER\")\r\n",
					"    print(\"Either due to the drive already been mounted, or because the path is incorrect\")"
				],
				"execution_count": 6
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 2. Get list of all rich media data in source folder\r\n",
					"This function is used to list out all the files of a type in a folder. This will be used during the later steps of the script."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Return array of all files in directory of type\r\n",
					"import os\r\n",
					"\r\n",
					"def get_blob_file_list(directory, filetype):\r\n",
					"    \"\"\"\r\n",
					"    Function to get a full list of files in a directory based on file type\r\n",
					"    Arguments:\r\n",
					"        directory: Directory path of folder you want to pull files from\r\n",
					"        filetype: .XXXX being the file extension of the file you are searching for (including a dot \".\")- ex- \".JPEG\" or \".JSON\"\r\n",
					"    Returns:\r\n",
					"        Array of filepaths/filename w/extension\r\n",
					"    \"\"\"\r\n",
					"    file_array = []\r\n",
					"    for file in os.listdir(directory):\r\n",
					"        file_ext = os.path.splitext(file)[1]\r\n",
					"        if file_ext == filetype:\r\n",
					"            file_array.append(directory+file)\r\n",
					"    return file_array"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Lets take a look at what these photos look like:"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Dispay first 5 images in blob storage\r\n",
					"import rasterio\r\n",
					"from rasterio.plot import show\r\n",
					"\r\n",
					"def view_images(directory):\r\n",
					"    \"\"\"\r\n",
					"    Function to view 5 images from a directory. Not used in the final workflow - just for show.\r\n",
					"    Arguments:\r\n",
					"        directory: Directory path of folder you want to display images of. Typically JPEG, GEOTIFF, etc ...\r\n",
					"    Returns:\r\n",
					"        Nothing\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    count = 0\r\n",
					"    for image in get_blob_file_list(directory):\r\n",
					"        if count >=5:\r\n",
					"            src = rasterio.open(directory+image)\r\n",
					"            show(src)\r\n",
					"            src.close()\r\n",
					"            count = count + 1"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 3. Setting up the collection\r\n",
					"\r\n",
					"We have already setup 2 collections in the destination folder titled \"rbu_mobile_oblique_imagery_for_ehsr_reporting\" and \"rbu_aerial_oblique_imagery_for_ehsr_reporting\"\r\n",
					"\r\n",
					"Note the difference of these two collection names and their folder path. In this scenario we are seperating JPEGs that were taken from drones (Aerial) and JPEGs that were taken from phones.\r\n",
					"\r\n",
					"We are organizing by \"oblique\" because we can assume that a majority (if not all) imagery we are consuming is of the type \"oblique\" to understand the definition of an oblique image, take a look at this image:\r\n",
					"\r\n",
					"![Oblique Image](http://3.bp.blogspot.com/-_dwZHYm-fTI/VdOTnSDGGUI/AAAAAAAAOiY/1SbT8RKhlYo/s1600/nadir_vs_oblique.png)\r\n",
					"\r\n",
					"Inside each collection is a json_mtl file which describes information about itself, and all the images in the collection folder. Lets take a look at that collection_mtl file to understand some more information about our collections."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Take a look at the collection MTL json files\r\n",
					"import json\r\n",
					"\r\n",
					"def check_collection_mtl(jsonpath):\r\n",
					"    \"\"\"\r\n",
					"    Print and return collection_mtl. Not used in the final workflow - just for show.\r\n",
					"    Arguments:\r\n",
					"        jsonpath: Path to json_mtl file\r\n",
					"    Returns:\r\n",
					"        json json_mtl file\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    json_open = json.load(open(jsonpath))\r\n",
					"    print(json_open)\r\n",
					"    return json_open"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 4. Extract EXIF Header Information\r\n",
					"Depending on the rich media data type, this step will be different. Between LAS files, GEOTIFFs, JPEGs, etc ... this step will have to be re-written to extract metadata from those files. \r\n",
					"\r\n",
					"This function is just used for returning/printing the metadata of the JPEG and is not currently used later on in this workflow."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import rasterio\r\n",
					"def extract_EXIF(jpeg_path):\r\n",
					"    \"\"\"\r\n",
					"    Function to list EXIF header information from the supplied JPEG. Not used in the final workflow - just for show.\r\n",
					"    Arguments:\r\n",
					"        jpeg_path: path to jpeg file\r\n",
					"    Returns:\r\n",
					"        Dictionary of EXIF Header information\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    file = rasterio.open(jpeg_path)\r\n",
					"    jpeg_EXIF = file.tags()\r\n",
					"    file.close()\r\n",
					"    return jpeg_EXIF"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 5. Extract Metadata\r\n",
					"Extracting the metadata of each JPEG is a tedious task that calls for automation. These next 4 funcitons extract/calculate metadata that STAC requires.\r\n",
					"\r\n",
					"### 5.1 Add Bounding Box\r\n",
					"### 5.2 Add DateTime\r\n",
					"### 5.3 Add CRS\r\n",
					"### 5.4 Add Sensor Type"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### 5.1 Bounding Box\r\n",
					"A bounding box is a concept that STAC requires, but not something that a JPEG has. To create a bounding box for a JPEG, we have to \"fake it\". In this scenario I am creating a fake 1 meter x 1 meter bounding box that STAC will recognize.\r\n",
					"\r\n",
					"To calculate a bounding box from a JPEG you must first do 3 things:\r\n",
					"- Extract lat/long from EXIF Header (including if coordinate direction is North/South or East/West)\r\n",
					"- Convert lat/long from EXIF Header from Degree, Minutes, Seconds to Decimal Degrees\r\n",
					"- Calculate new bounding box\r\n",
					"- Return new bounding box\r\n",
					"\r\n",
					"Lastly, the data must be inserted into the \"headers\" of the JPEG. Since JPEG does not natively support adding to headers, a XML file is created via rasterio. This step will be done once we move the new images into the right folder."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import rasterio\r\n",
					"\r\n",
					"def get_EXIF_lat(jpeg_path):\r\n",
					"    \"\"\"\r\n",
					"    Function to get the Latitude of a JPEG image\r\n",
					"    Arguments:\r\n",
					"        jpeg_path: path to jpeg file\r\n",
					"    Returns:\r\n",
					"        string of latitude in format of (dd) (mm) (ss.sss) & GPS Reference in terms of (S or N)\r\n",
					"    \"\"\"\r\n",
					"    jpeg = rasterio.open(jpeg_path)\r\n",
					"    filetags = jpeg.tags()\r\n",
					"    GPSLatitude = filetags.get(\"EXIF_GPSLatitude\")\r\n",
					"    GPSLatitudeRef = filetags.get(\"EXIF_GPSLatitudeRef\")\r\n",
					"    jpeg.close()\r\n",
					"    return GPSLatitude, GPSLatitudeRef\r\n",
					"\r\n",
					"def get_EXIF_long(jpeg_path):\r\n",
					"    \"\"\"\r\n",
					"    Function to get the Longitude of a JPEG image\r\n",
					"    Arguments:\r\n",
					"        jpeg_path: path to jpeg file\r\n",
					"    Returns:\r\n",
					"        string of longitude in format of (dd) (mm) (ss.sss) & GPS Reference in terms of (W or E)\r\n",
					"    \"\"\"\r\n",
					"    jpeg = rasterio.open(jpeg_path)\r\n",
					"    filetags = jpeg.tags()\r\n",
					"    GPSLongitude = filetags.get(\"EXIF_GPSLongitude\")\r\n",
					"    GPSLongitudeRef = filetags.get(\"EXIF_GPSLongitudeRef\")\r\n",
					"\r\n",
					"    jpeg.close()\r\n",
					"    return GPSLongitude, GPSLongitudeRef"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def Exif_Cord_Convert(EXIF_Cord, direction):\r\n",
					"    \"\"\"\r\n",
					"    Function to convert coordinate from get_EXIF_long + get_EXIF_lat functions (dd)(mm)(ss.sss) to decimal degrees.\r\n",
					"    Arguments:\r\n",
					"        EXIF_Cord: return from get_EXIF_long or get_EXIF_lat (first return)\r\n",
					"        direction: return from get_EXIF_long or get_EXIF_lat (second return) - Either as \"N\",\"S\",\"E\", or \"W\"\r\n",
					"    Returns:\r\n",
					"        Decimal Degrees of coordinate.\r\n",
					"    \"\"\"\r\n",
					"    new_str = EXIF_Cord.replace(\"(\",\"\")\r\n",
					"    new_str = new_str.replace(\")\",\"\")\r\n",
					"\r\n",
					"    split_str = new_str.split(\" \")\r\n",
					"    \r\n",
					"    decimaldegrees = (float(split_str[0]) + float(split_str[1])/60 + float(split_str[2])/(60*60)) * (-1 if direction in ['W', 'S'] else 1)\r\n",
					"    return decimaldegrees"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import pyproj\r\n",
					"from shapely.ops import transform\r\n",
					"from shapely.geometry import Point\r\n",
					"from functools import partial\r\n",
					"\r\n",
					"def calculate_bb(lat, lon):\r\n",
					"    \"\"\"\r\n",
					"    Function to calculate a \"fake\" bounding box of 1m by 1m given a lat/long coordinate in Decimal Degrees. The lat/long is assumed to be in WGS84.\r\n",
					"    Arguments:\r\n",
					"        lat: latitude in decimal degrees\r\n",
					"        long: longitude in decimal degrees\r\n",
					"    Returns:\r\n",
					"        array of bounding box to be used for metadata of JPEG.\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    proj_wgs84 = pyproj.Proj('+proj=longlat +datum=WGS84')\r\n",
					"    \r\n",
					"    # Azimuthal equidistant projection\r\n",
					"    aeqd_proj = '+proj=aeqd +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0'\r\n",
					"    project = partial(\r\n",
					"        pyproj.transform,\r\n",
					"        pyproj.Proj(aeqd_proj.format(lat=lat, lon=lon)),\r\n",
					"        proj_wgs84)\r\n",
					"    \r\n",
					"    buf = Point(0, 0).buffer(1)  # buffers 1 meter\r\n",
					"    return transform(project, buf).bounds"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def get_bb(jpeg_path):\r\n",
					"    \"\"\"\r\n",
					"    Function to return a faked bounding box using previous functions.\r\n",
					"    Arguments:\r\n",
					"        jpeg_path: path to JPEG which you want faked bounding box from. JPEG must have Latitude/Longitude in EXIF header.\r\n",
					"    Returns:\r\n",
					"        array of bounding box to be used for metadata of JPEG.\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    EXIFlat, latRef = get_EXIF_lat(jpeg_path)\r\n",
					"    EXIFlong, longRef = get_EXIF_long(jpeg_path)\r\n",
					"\r\n",
					"    lat = Exif_Cord_Convert(EXIFlat,latRef)\r\n",
					"    long = Exif_Cord_Convert(EXIFlong,longRef)\r\n",
					"\r\n",
					"    return calculate_bb(lat,long)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### 5.2 Add Date Time\r\n",
					"\r\n",
					"The STAC spec calls for a datetime to be added to the headers of the files. For this use case, EXIF information includes this data, but we have to get it into the right format. To do this, we will extract the EXIF Datetime and convert it to the STAC-ready format.\r\n",
					"\r\n",
					"In some instances, rich media is captured over a range of time (videos, stiched together aerial GEOTIFFs, and point clouds). For any of those use cases, a new function would have to be created to return a start_datetime and an end_datetime to fit to the STAC standard.\r\n",
					"\r\n",
					"This step will be done once we move the new images into the right folder."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from datetime import datetime\r\n",
					"\r\n",
					"#Output date time must be in \r\n",
					"def get_jpeg_datetime(jpeg_path):\r\n",
					"    \"\"\"\r\n",
					"    Function to return a STAC-customized DateTime from JPEG image EXIF information.\r\n",
					"    Arguments:\r\n",
					"        jpeg_path: path to JPEG which you want STAC-DateTime for. JPEG must have DateTime in EXIF header.\r\n",
					"    Returns:\r\n",
					"        STAC-Specific DateTime as a string\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    jpeg = rasterio.open(jpeg_path)\r\n",
					"    filetags = jpeg.tags()\r\n",
					"    jpeg.close()\r\n",
					"    EXIF_Datetime = filetags.get(\"EXIF_DateTime\")\r\n",
					"    EXIF_datetime_obj = datetime.strptime(EXIF_Datetime, '%Y:%m:%d %H:%M:%S')\r\n",
					"    STAC_datetime = EXIF_datetime_obj.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\r\n",
					"    return STAC_datetime"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### 5.3 Add Coordinate Reference System\r\n",
					"The Cordinate Reference System (CRS) of a JPEG is usually taken in WGS84 (since that is the datum GPS is based on). Sometimes there will be a GPSMapDatum in the EXIF header but usually this data is not captured (much to the chagrin of geospatial analysts everywhere). For example if the image was taken in Japan, this value will be \"TOKYO\" but for this data, none is given. \r\n",
					"\r\n",
					"We will assume the data is GPS-WGS84 which has a [European Petroleum Survey Group (EPSG)](https://support.esri.com/en/technical-article/000002814#:~:text=Answer,version%20of%20the%20EPSG%20model.) standard ID of \"4326\" or otherwise captured as [EPSG:4326](https://epsg.io/4326)"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def get_jpeg_crs(jpeg_path):\r\n",
					"    \"\"\"\r\n",
					"    Function to return \"EPSG:4326\"\r\n",
					"    Arguments:\r\n",
					"        jpeg_path: not used, but still good practice if we want to extend this function\r\n",
					"    Returns:\r\n",
					"        EPSG:4326 as a string which is the GPS-WGS84 Cordinate Reference System\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    crs = \"EPSG:4326\"\r\n",
					"    return crs"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### 5.4 Add Sensor Type\r\n",
					"Determining sensor type is important when you know your datasets will contain rich media from multiple sensors. Here we define sensor as the optical capturing device's binary return. For example, this RBU imagery was captured with an RGB (Red, Green, Blue) sensor, but there are other sensors we have recognized such as Near-Infrared (NIR), Radar, and Multispectral. \r\n",
					"\r\n",
					"[Check NASA's website](https://www.earthdata.nasa.gov/sensors) for an almost exhaustive list of remote sensing sensors. There is no standard yet set for how we want the sensor formated in STAC. More to come on this.\r\n",
					"\r\n",
					"For this dataset, we will return RGB because every imagery taken, we can assume, was taken by an RGB camera."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def get_jpeg_sensor(jpeg_path):\r\n",
					"    \"\"\"\r\n",
					"    Function to return \"RGB\"\r\n",
					"    Arguments:\r\n",
					"        jpeg_path: not used, but still good practice if we want to extend this function\r\n",
					"    Returns:\r\n",
					"        RGB as a string\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    sensor_type = \"RGB\"\r\n",
					"    return sensor_type"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 6. Mobile or Aerial image?\r\n",
					"\r\n",
					"Based of the proposed architecture, it is important to sort the imagery between \"Mobile\" and \"Drone\" since those are 2 different types of collections. How will we be able to do that on these images?\r\n",
					"\r\n",
					"Luckily, we know that in this use case, RBU is using \"DJI\" drones (commerical-company) which use DJI cameras. If you look in the EXIF header of the imagery you can see an attribute called \"EXIF_Make\" which contains the information about the camera maker. This item will contain:\r\n",
					"1. DJI\r\n",
					"2. Android\r\n",
					"3. Apple\r\n",
					"4. ... other mobile phones\r\n",
					"5. Blank\r\n",
					"\r\n",
					"If we test between all RBU imagery if it is \"DJI imagery\" and \"everything else\" we can then sort between \"drone\" and \"mobile\" respectively"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Return true if image was taken from drone\r\n",
					"def is_drone(jpeg_path):\r\n",
					"    \"\"\"\r\n",
					"    Function to determine if image was taken form a drone (Assuming drone is a DJI drone)\r\n",
					"    Arguments:\r\n",
					"        jpeg_path: path to JPEG you want to determine if taken from a drone or not.\r\n",
					"    Returns:\r\n",
					"        True if taken from a drone, otherwise returns False\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    jpeg = rasterio.open(jpeg_path)\r\n",
					"    filetags = jpeg.tags()\r\n",
					"    \r\n",
					"    jpeg.close()\r\n",
					"    platform = filetags.get(\"EXIF_Make\")\r\n",
					"    \r\n",
					"    if platform == 'DJI':\r\n",
					"        return True\r\n",
					"    else:\r\n",
					"        return False    "
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## 7. Write to Collection - w/Added Metadata\r\n",
					"Finally we get into the big task of reading from the STAC Source and writing to the STAC Destination. Here are the steps we have defined:\r\n",
					"1. Get list of all JPEGs (using the function in step 2)\r\n",
					"2. Determine which JPEG fits into which collection (using function in step 6)\r\n",
					"3. Get list of all metadata components to be added (using function in step 5)\r\n",
					"4. Write to collection folder w/metadata added\r\n",
					"5. Celebrate ðŸ™Œ"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import rasterio\r\n",
					"from notebookutils import mssparkutils\r\n",
					"import os\r\n",
					"\r\n",
					"def write_to_collection(jpeg_path, collection_path):\r\n",
					"    \"\"\"\r\n",
					"    Currently running into issues on copying the files. This step may be best done with a data pipeline outside of this script? For now, I have manually moved the files to the right folders.\r\n",
					"    \"\"\"\r\n",
					"    print(collection_path)\r\n",
					"    BoundingBox = get_bb(jpeg_path)\r\n",
					"    DateTime = get_jpeg_datetime(jpeg_path)\r\n",
					"    jpeg_CRS = get_jpeg_crs(jpeg_path)\r\n",
					"    Sensor = get_jpeg_sensor(jpeg_path)\r\n",
					"\r\n",
					"    with rasterio.open(\r\n",
					"            collection_path,\r\n",
					"            'r+',\r\n",
					"            driver='JPEG') as dst:\r\n",
					"            dst.update_tags(datetime = DateTime, start_datetime = None, end_datetime = None, bbox = BoundingBox, crs = jpeg_CRS, sensor = Sensor)\r\n",
					"            print(\"Added metadata to \"+ collection_path)\r\n",
					"            dst = None\r\n",
					"\r\n",
					"    return True"
				],
				"execution_count": 174
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Below is where we run the whole script. I have not wrote it into a function as of yet."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import os\r\n",
					"\r\n",
					"jobId = mssparkutils.env.getJobId()\r\n",
					"img_path = f'/synfs/'+jobId+'/STAC_Source/RBU_STAC_SOURCE/'\r\n",
					"outarray = get_blob_file_list(img_path, \".JPG\")\r\n",
					"#print(outarray)\r\n",
					"\r\n",
					"oblique_mobile_path = f'/synfs/'+jobId+'/STAC_Dest/RBU_STAC_DEST/Mobile/Oblique/rbu_mobile_oblique_imagery_for_ehsr_reporting/'\r\n",
					"oblique_aerial_path = f'/synfs/'+jobId+'/STAC_Dest/RBU_STAC_DEST/Aerial/Oblique/rbu_aerial_oblique_imagery_for_ehsr_reporting/'\r\n",
					"\r\n",
					"for jpeg in outarray:\r\n",
					"    filename = os.path.basename(jpeg)\r\n",
					"    print(filename)\r\n",
					"\r\n",
					"    if is_drone(jpeg):\r\n",
					"        write_to_collection(jpeg, oblique_aerial_path+filename)\r\n",
					"\r\n",
					"    else:\r\n",
					"        write_to_collection(jpeg, oblique_mobile_path+filename)"
				],
				"execution_count": 179
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Georeferenced TIFF STAC\r\n",
					"Up till now we have created functions for finding and creating metadata for oblique images, but what about _Georeferenced Imagery_? A georeferenced image is an image where all four corners fit into a real world space. When you pull this type of imagery into certain geospatial softwares like ArcGIS Pro, GlobalMapper, ENVI, AzureMaps ... the software will project the image into real world space. Originally this type of data was what the STAC spec was built off of and there are many resources built around it. Lets investigate Georeferenced Imagery (in the form of a GEOTIFF).\r\n",
					"\r\n",
					"The STACify process is able to read the metadata of GEOTIFFs very well so we will not have to reformat many metadata components. Unlike oblique imagery GeoTiffs innately have bounding boxes, so, we will not need to create one within the headers. Also CRS is something that most images come with innately in their headers. We will not need to create a function to create this. We will still need Date Time, and Sensor Type however. Lets create some functions!"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### GeoTIFF Metadata\r\n",
					"1. Date Time\r\n",
					"2. Sensor Type"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Currently not implemented\r\n",
					"from osgeo import gdal\r\n",
					"\r\n",
					"def get_geotiff_datetime(geotiff_path):\r\n",
					"    \"\"\"\r\n",
					"    Function to return a STAC-customized DateTime from GEOTIFF GDAL_Metadata\r\n",
					"    Arguments:\r\n",
					"        geotiff_path: path to GeoTIFF which you want STAC-DateTime for. GeoTIFF that was used in this situation has an acquisitionEndDate and acquisitionStartDate in GDAL Metadata header.\r\n",
					"    Returns:\r\n",
					"        STAC-Specific DateTime as a string\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    gtiff = gdal.Info(geotiff_path)\r\n",
					"    print(gtiff)"
				],
				"execution_count": 10
			}
		]
	}
}